
        # # # s3_df = spark.read.json(sc.parallelize([json_content]))
        s3_df.show()
        #s3_df.show()
        s3_df_clean = s3_df.drop(s3_df._corrupt_record)
        s3_df_clean = s3_df_clean.dropna()
        #s3_df_clean = s3_df_clean.drop(" _corrupt_record")
        s3_df_clean.show()
        # # s3_df.printSchema()
        # # # s3_df_a.show()
